### Kafka Installation
[Apache Kafka](https://kafka.apache.org/) is an open-source stream-processing software platform.

**Install Kafka and Zookeeper services:**

Create docker-compose file for services:
```shell
nano docker-compose.yml
```
{: .copy-code}

Add the following line to the yml file:
```yml
services:
  zookeeper:
    restart: always
    image: "zookeeper:3.5"
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zookeeper:2888:3888;zookeeper:2181
  kafka:
    restart: always
    image: wurstmeister/kafka:13-3.0.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
```
{: .copy-code}

Where:
- `restart:` `always` - automatically start Kafka service in case of system reboot and restart in case of failure.;
- `Ports:` `2181:2181` - connect local port 2181 to exposed internal zookeeper port zookeeper;
- `Ports:` `9092:9092` - connect local port 9092 to exposed internal kafka port kafka;

Then, from the folder with this file, run the command:
```shell
docker-compose up -d
```
{: .copy-code}

**Create Uplink Converter**

To create **Uplink converter**, go to the **Data Converters** section and click **Add Data Converter**, then **Create New Converter**. Name it "**Uplink (Kafka)**" and select the **uplink** type. Use debug mode when you need to parse decoder events.

{% capture kafka_please_note %}
**Note:** While debug mode is very useful for development and troubleshooting, leaving it enabled in production mode can significantly increase the disk space used by the database since all debug data is stored there. After debugging is complete, it is highly recommended turning off debug mode.
{% endcapture %}
{% include templates/info-banner.md content=kafka_please_note %}

You can use the following code, copy it to the decoder function section:

```js
// Decode an uplink message from a buffer
// payload - array of bytes
// metadata - key/value object

/** Decoder **/
// decode payload to JSON
var payloadJsn = decodeToJson(payload);

// decode payload to String
// var payloadStr = decodeToString(payload);

// var groupName = 'thermostat devices';
// use assetName and assetType instead of deviceName and deviceType
// to automatically create assets instead of devices.
// var assetName = 'Asset A';
// var assetType = 'building';

// Result object with device/asset attributes/telemetry data
   var result = {
// Use deviceName and deviceType or assetName and assetType, but not both.
   deviceName: payloadJsn.deviceName,
   deviceType: payloadJsn.deviceType,
// assetName: assetName,
// assetType: assetType,
   attributes: payloadJsn.attributes,
   telemetry: payloadJsn.telemetry
};

/** Helper functions **/
function decodeToString(payload) {
   return String.fromCharCode.apply(String, payload);
}

function decodeToJson(payload) {
   // covert payload to string.
   var str = decodeToString(payload);
   // parse string to JSON
   var data = JSON.parse(str);
   return data;
}

return result;
```
{: .copy-code}

Example of payload:
```json
{
        "deviceName":"SN-111",
        "deviceType":"default",
        "attributes":{
            "model":"Model A"
        },
        "telemetry":[
            {
              "ts":1607731932000,
              "values":{
                  "battery":3.99,
                  "temperature":27.05
              }
            },
            {
              "ts":1634608351000,
              "values":{
                  "battery":3.14,
                  "temperature":27.51
        }}]
}
```
{: .copy-code}

{% include images-gallery.html imageCollection="Create Uplink Converter" %}

You can change the parameters and decoder code when creating a converter or editing. If the converter has already been created, click the pencil icon to edit it. Copy the sample converter configuration (or use your own configuration) and paste it into the decoder function. Then save the changes by clicking the checkmark icon.


**Create Integration**

After creating the Uplink converter, it is possible to create an integration. Required fields: Name, Type, Topics

{% include images-gallery.html imageCollection="Kafka Integration" %}

With these settings, the integration will request updates from the Kafka broker every 5 seconds. And if set a topic does not exist at the broker, it will be created automatically.

**Send test Uplink message**

You can simulate a message from a device or server using a terminal. To send an uplink message, you need a Kafka endpoint URL from the integration.
```shell
echo "{\"deviceName\":\"SN-111\",\"deviceType\":\"default\",\"attributes\":{\"model\":\"Model A\"},\"telemetry\":[{\"ts\":1527863143000,\"values\":{\"battery\":9.99,\"temperature\":27.99}},{\"ts\":1527863044000,\"values\":{\"battery\":9.99,\"temperature\":99.99}}]}" | /usr/local/kafka/bin/kafka-console-producer.sh --broker-list YOUR_KAFKA_ENDPOINT_URL:9092 --topic my-topic > /dev/null
```
{: .copy-code}

Result:

{% include images-gallery.html imageCollection="Kafka_integration_test_send_msg_result" %}

Also, you can check through the terminal what data came to Kafka.
```yml
/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server YOUR_KAFKA_ENDPOINT_URL:9092 --topic my-topic --from-beginning
```
{: .copy-code}